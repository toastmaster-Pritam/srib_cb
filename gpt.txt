[*] Generating synthetic OBP bandit data...
  n_rounds=2000, n_actions=10, dim=12
[*] Synthesizing 10-day short-term histories and true long-term (L)...
[*] Training RF to predict L_true using context + first 5 days short features...
  RF trained. test R^2 (approx): 0.4552099214552878
[*] Learning composite parameters alpha and beta via small gradient fit...
  learned alpha = 0.06665080785751343 beta = [0.23251136 0.27525592 0.4922327 ]
[*] Building LinUCB sufficient stats (A, b) from synthetic data...
[*] Computing target policy distributions...
[*] Running offline policy evaluation (IPS / SNIPS / DR)...
  uniform | IPS=0.3792 SNIPS=0.3792 DR=0.3792 approx_true=0.3792
  linucb  | IPS=0.3860 SNIPS=0.3794 DR=0.3792 approx_true=0.3792
[*] Estimated uplift (linucb vs uniform) by DR = -0.000000
[*] Saving cumulative expected reward plot...
  saved: outputs/cum_reward_offline.png
/home/pritam/obp/offline_train_eval.py:273: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  "timestamp": datetime.utcnow().isoformat() + "Z"
[*] Summary saved to outputs/summary_offline.json
[*] Done.
