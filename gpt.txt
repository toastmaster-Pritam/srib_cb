[*] Generating synthetic OBP bandit data...
  n_rounds=5000, n_actions=10, dim=12
[*] Synthesizing 10-day short-term histories and true long-term (L)...
[*] Training RF to predict L_true using context + first 3 days short features...
  RF trained. test R^2 (approx): 0.0
[*] Learning composite parameters alpha and beta via small gradient fit...
  learned alpha = 0.0687311589717865 beta = [0.0615074  0.05213882 0.8863538 ]
[*] Building LinUCB sufficient stats (A, b) from synthetic data...
[*] Computing target policy distributions...
[*] Running offline policy evaluation (IPS / SNIPS / DR)...
  uniform | IPS=0.9636 SNIPS=0.9636 DR=0.9636 approx_true=0.9636
  linucb  | IPS=0.9828 SNIPS=0.9636 DR=0.9636 approx_true=0.9636
[*] Estimated uplift (linucb vs uniform) by DR = 0.000000
[*] Saving cumulative expected reward plot...
  saved: outputs/cum_reward_offline.png
/home/pritam/obp/offline_train_eval.py:271: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  "timestamp": datetime.utcnow().isoformat() + "Z"
[*] Summary saved to outputs/summary_offline.json
[*] Done.
